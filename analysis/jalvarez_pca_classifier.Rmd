---
title: "Ancestry classifier with principal components"
output:
  html_document:
    df_print: paged
  pdf_document: default
editor_options: 
  markdown: 
    wrap: 72
---

## 00. Approximately 2% of 2.2 million variants were filtered for analysis

The following criteria were applied to filter the original VCF to 42,427
variants:

-   SNPs only
-   Minor allele frequency greater than 1%
-   High call rate such that the variant is reported in at least 95% of
    samples
-   LD-pruned where r^2^ \< 0.1
-   Correctly stranded compared to reference genome--if unresolved with
    VCF QC tools then excluded

Afterwards, the data was converted into PLINK format then read into R.

```{bash echo=TRUE}
INFILE=data/acs_mini_project ; \
OUTFILE=data/acs_mini_project.2plink

bcftools view -m2 -M2 -v snps ${INFILE}.vcf.gz | bcftools +prune -l 0.1 | bcftools +fill-tags | \ 
bcftools filter -e 'AF < 0.01' | bcftools filter -e 'F_MISSING >= 0.05' | bgzip -c > \ 
${INFILE}.filtered.vcf.gz

plink --vcf data/${INFILE}.vcf.gz --make-bed --snps-only --out ${OUTFILE}
```

Once read into R, the genotype table was checked for samples with high
proportion of missing data. 107 samples with at least 10% missing data
were removed from the analysis. This is a 5% loss from the original 1966
samples. Variants with missing values were also removed, resulting in an
approximately 20% reduction from original down to 34,655 variants.
Although the data loss may be noticeable enough to affect downstream
analysis, the filtering done beforehand ensures that the retained data
is still of high quality.

```{r setup, eval = FALSE}
knitr::opts_chunk$set(cache = TRUE, echo = TRUE)
library(tidyverse)
library(magrittr)
library(DT)
library(adegenet)
library(GGally)
library(RColorBrewer)
library(ggnewscale)
library(caret)
library(rpart)
# library(rattle)
# library(partykit)
library(ggdendro)

source(file = "../code/00_helper.R")

fname <- "../data/acs_mini_project.2plink"
dat <- adegenet::read.PLINK(paste0(fname,".raw"))
adegenet::indNames(dat) <- paste0("TGG_", adegenet::indNames(dat))
labels <- readr::read_delim("../data/acs_mini_project_labels.txt")
adegenet::pop(dat) <- labels$ancestry %>% unlist() %>% as.factor()

gt <- as.matrix(dat)

missing_smpl <- apply(gt, 1, function(x) {sum(is.na(x))/nrow(gt)})
miss_smpl_idx <- which(missing_smpl > 0.1)
gt <- gt[-miss_smpl_idx,] %>% t() %>% na.omit() %>% t()

labels <- labels[-miss_smpl_idx,]
lbl_idx <- which(!is.na(labels$ancestry))
lbl_gt <- gt[lbl_idx, ]

set.seed(63549)

trn_idx <- sample(1:nrow(lbl_gt), nrow(lbl_gt) * 0.8, replace = F)
trn_data <- lbl_gt[trn_idx, ]

trn_data %<>% apply(2, function(x) {x - mean(x, na.rm = T)})

trn_pca <- prcomp(trn_data, center = F, scale. = F)

trn_pve <- data.frame(
  pc = seq(length(trn_pca$sdev)),
  pve = trn_pca$sdev^2 / sum(trn_pca$sdev^2),
  cumsum_pve = cumsum(trn_pca$sdev^2 / sum(trn_pca$sdev^2)))
```

Make plot.

```{r, eval = FALSE}
ggplot2::ggplot(dplyr::filter(trn_pve, pc <= 10), aes(x = pc, y = pve * 100)) +
  geom_line(stat = "identity") +
  scale_x_continuous(breaks = c(0, seq(10))) + 
  scale_y_continuous(breaks = c(0, seq(1, 10, 2))) +
  ylab("Proportion of variance \nexplained (%)") +
  xlab("Principal component (PC)") + ylim(0, 10) +
  ggplot2::theme(text = element_text(size = 20))

mywidth <- 2250
ggplot2::ggsave("../output/00_labeled_scree.tiff", device = "tiff", units = "px", 
                width = mywidth, height = mywidth * 0.75, dpi = "print")

```

## 01. First 3 principal components capture 46% of variance explained

The genotypes of labeled samples were used to generate principal
components used to predict ancestry of unlabeled samples. After
excluding the unlabeled samples, the remaining genotypes were randomly
sampled into training and test sets, composed of 80% and 20% of all
labeled samples respectively. The training set of 869 labeled samples
was mean-centered to 0 to let samples be more comparable to each other.
Data were not scaled by standard deviation since all values represent
the same measure of 0-2 alternate alleles called for a given variant.
The centered training set was then used for PCA.

```{r, eval = FALSE}
retx <- as.data.frame(trn_pca$x) %>% 
  tibble::rownames_to_column("sample_id") %>% 
  dplyr::left_join(labels, by = "sample_id") %>% 
  dplyr::relocate(sample_id, ancestry) %>% 
  dplyr::select(sample_id:PC3)

pca_matrix <- ggpairs(retx, columns = paste0("PC", seq(3)),
                    upper = NULL, lower = NULL, diag = NULL, 
                    progress = F, legend = GGally::grab_legend(trn_plot(1, 2)),
                    switch = "both")

for (j in c(1,2)) {
  for (i in c(2,3)) {
    if (i > j) {
      pca_matrix[i, j] <- trn_plot(j, i)
      }
  }
}

for (i in seq(3)) {
  pca_matrix[i,i] <- ggally_text(
    paste0("PC", i," (", round(trn_pve$pve[i], 3) * 100, "%\nof variance\nexplained)"),
    mapping = ggplot2::aes(size = 1), color = I("black")) +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
          axis.ticks = element_blank(), axis.ticks.y = element_blank(), 
          axis.text.y = element_blank())
}

pca_matrix
ggplot2::ggsave("output/00_labeled_PCA.tiff", device = "tiff", units = "px", 
                width = mywidth, height = mywidth * 0.75, dpi = "print")
```

The scree plot `01_scree_plot.png` of the computed PCs indicates that most of the observed
variance is captured by the first 5 principal components, cumulatively
explaining 15% of variance explained. Only the first 5 were chosen due
to the diminishing proportion values. Also, only the first 3 eigenvalues
are greater than 1, indicating that very little variability can be
described with increased number of PCs.

The whole genotype table, including the unlabeled and test samples, were
then projected to the eigenvectors of the PCA analysis. The PC values
for all samples can be found in `01_gt_pca_evec.txt`.

## 02. KNN model was trained to predict ancestry with 3% error rate and k = 20

K-nearest neighbors (KNN) was chosen using the first 5 principal
components as features to predict most likely ancestry of a given
sample. KNN was chosen because it is a non-parametric method and no
assumptions were made about the distribution of the PC values. Because
the reported ancestries of the labeled samples are known, the model can
be evaluated by measuring the proportion of correctly predicted labels
with increasing numbers of k. Once there is no longer an appreciable
change in model accuracy then an appropriate value of k to use for the
unlabeled samples can be selected.

```{r echo=TRUE, knn, fig.align='center'}
projected_retx <- predict(trn_pca, gt) %>%
  as.data.frame() %>% 
  tibble::rownames_to_column("sample_id") %>% 
  dplyr::left_join(labels, by = "sample_id") %>% 
  dplyr::relocate(sample_id, ancestry)

evec_lbl <- projected_retx %>% 
  dplyr::select(sample_id:PC3) %>% 
  tibble::column_to_rownames("sample_id") %>% 
  dplyr::filter(!is.na(ancestry)) %>% 
  dplyr::mutate(ancestry = as.factor(ancestry))

evec_unl <- projected_retx %>% 
  dplyr::select(sample_id:PC3) %>% 
  tibble::column_to_rownames("sample_id") %>% 
  dplyr::filter(is.na(ancestry)) %>% 
  dplyr::select(-ancestry)

evec_trn <- evec_lbl[trn_idx,-1]
evec_tst <- evec_lbl[-trn_idx, -1]
trn_pop <- as.factor(evec_lbl[trn_idx,1])
tst_pop <- as.factor(evec_lbl[-trn_idx,1])

set.seed(63549)
k_times <- 30

trn_err <- rep(0, k_times)
tst_err <- rep(0, k_times)

list_trn_strt <- list()
list_tst_strt <- list()

for(k in seq(k_times)){
  knn_trn <- class::knn(train = evec_trn, test = evec_trn, cl = trn_pop, k = k, prob = F)
  conf_trn <- caret::confusionMatrix(data = knn_trn, reference = trn_pop)
  trn_err[k] = 1 - conf_trn$overall["Accuracy"]
  list_trn_strt[[k]] <- data.frame(
    k = k, afr_err = 1 - conf_trn$byClass["Class: afr",]["Balanced Accuracy"], 
    amr_err = 1 - conf_trn$byClass["Class: amr",]["Balanced Accuracy"], 
    eas_err = 1 - conf_trn$byClass["Class: eas",]["Balanced Accuracy"], 
    fin_err = 1 - conf_trn$byClass["Class: fin",]["Balanced Accuracy"], 
    nfe_err = 1 - conf_trn$byClass["Class: nfe",]["Balanced Accuracy"], 
    sas_err = 1 - conf_trn$byClass["Class: sas",]["Balanced Accuracy"]
    )

  knn_tst <- class::knn(train = evec_trn, test = evec_tst, cl = trn_pop, k = k, prob = F)
  conf_tst <- confusionMatrix(data = knn_tst, reference = tst_pop)
  tst_err[k] = 1 - conf_tst$overall["Accuracy"]
  list_tst_strt[[k]] <- data.frame(
    k = k, afr_err = 1 - conf_tst$byClass["Class: afr",]["Balanced Accuracy"], 
    amr_err = 1 - conf_tst$byClass["Class: amr",]["Balanced Accuracy"], 
    eas_err = 1 - conf_tst$byClass["Class: eas",]["Balanced Accuracy"], 
    fin_err = 1 - conf_tst$byClass["Class: fin",]["Balanced Accuracy"], 
    nfe_err = 1 - conf_tst$byClass["Class: nfe",]["Balanced Accuracy"], 
    sas_err = 1 - conf_tst$byClass["Class: sas",]["Balanced Accuracy"]
    )
  }

full_trn_strt <- do.call(rbind, list_trn_strt)
rownames(full_trn_strt) <- NULL

full_trn_df <- full_trn_strt %>% 
  tidyr::pivot_longer(
    cols = c(afr_err, amr_err, eas_err, fin_err, nfe_err, sas_err),
    names_to = "pop", values_to = "err")

ggplot2::ggplot(dplyr::filter(full_trn_df, pop %in% c("amr_err", "fin_err","nfe_err")),
                ggplot2::aes(x = 1/k, y = err * 100, color = pop)) + geom_line() +
  ggplot2::xlab("1/k") + ggplot2::ylab("Error rate (%)") +
  scale_color_manual(values = brewer.pal(6, "Set2"), name = "Ancestry")
ggplot2::ggsave("output/02_KNN_trn_strt.tiff", device = "tiff", units = "px", 
                width = mywidth, height = mywidth * 0.75, dpi = "print")

full_tst_strt <- do.call(rbind, list_tst_strt)
rownames(full_tst_strt) <- NULL

full_tst_df <- dplyr::filter(full_tst_strt, pop %in% c("amr_err", "fin_err","nfe_err")) %>% 
  tidyr::pivot_longer(
    cols = c(afr_err, amr_err, eas_err, fin_err, nfe_err, sas_err),
    names_to = "pop", values_to = "err")

ggplot2::ggplot(dplyr::filter(full_tst_df, pop %in% c("amr_err", "fin_err","nfe_err")), 
                ggplot2::aes(x = 1/k, y = err * 100, color = pop)) + geom_line() +
  ggplot2::xlab("1/k") + ggplot2::ylab("Error rate (%)") +
  scale_color_manual(values = brewer.pal(6, "Set2"), name = "Ancestry")
ggplot2::ggsave("output/02_KNN_tst_strt.tiff", device = "tiff", units = "px", 
                width = mywidth, height = mywidth * 0.75, dpi = "print")
```

```{r}

knn_df <- data.frame(k = seq(k_times), trn_err = trn_err, tst_err = tst_err) %>% 
  tidyr::pivot_longer(cols = c(trn_err, tst_err), names_to = "grouping", values_to = "prop")

ggplot2::ggplot(knn_df, ggplot2::aes(x = 1/k, y = prop * 100, color = grouping)) +
  geom_line() +
  ggplot2::xlab("1/k") +ggplot2::ylab("Error rate (%)") +
  theme(legend.title = element_blank()) +
  scale_color_manual(name = "val", 
                     labels=c("Training", "Test"), 
                     values = brewer.pal(3, "Dark2")[1:2])

class_conf <- as.data.frame(conf_tst$byClass)

dplyr::filter(knn_df, grouping == "tst_err") %>% 
  dplyr::summarise(min = min(prop)) %>%  
  as.numeric() * 100

mywidth <- 2250
ggplot2::ggsave("output/02_KNN_training.tiff", device = "tiff", units = "px", 
                width = mywidth, height = mywidth * 0.75, dpi = "print")
```

The selected number for the maximum number of k is 30, the square root
of the number of samples in the training set. Starting from k = 1, the
training set was used to predict ancestries of samples from both
training and test sets. The error rate appears to increase very little
around k = 20, which was later used for predicting the unlabeled
samples. This plot can be found in `02_knn_plot.png`.

The table of all samples and their ancestries, either predicted or
already labeled, can be found below.

```{r echo=TRUE, predict, fig.align='center'}
prd_unl <- class::knn(train = evec_trn, test = evec_unl, cl = trn_pop, k = 20, prob = F)

evec[is.na(evec$ancestry),"ancestry"] <- as.character(prd_unl)
evec_df <- evec %>% 
  dplyr::mutate(grouping = as.character(sample_id %in% rownames(lbl_gt))) %>% 
  dplyr::mutate(grouping = tolower(grouping)) %>% 
  dplyr::relocate(sample_id, ancestry, grouping)

evec_df$grouping[evec_df$grouping == "true"] <- "labeled"
evec_df$grouping[evec_df$grouping == "false"] <- "predicted"
levels(evec_df$grouping) <- c("labeled", "predicted")

# DT::datatable(evec_df, options = list(scrollX = T))
write.table(evec_df, "output/02_predicted_ancestry.txt", col.names = T, row.names = F, 
            quote = F, sep = "\t")
```

## Distributions of PC values shared between labeled and predicted samples

The PC values for each sample across the first 5 principal components
are shown in pairwise fashion below. Each sample is colored by their
reported ancestry. In addition, a second set of plots colored by whether
a given sample was labeled in the original dataset was shown as if it
can be overlaid on the population-level PCA.

The labels for each principal component are positioned to correspond to
the axis they're plotted in. For example, to see the ancestry-colored
plot for "PC2 vs PC1", start at the second row at the "PC2" label along
the y-axis at the right of plot then move to the 1st column, where "PC1"
is labeled on the x-axis at the bottom of the plot. The corresponding
plot for labeled vs unlabeled samples can be found by following the
inverse of the previous step or moving diagonally from the first plot.

```{r echo=TRUE, all_pcs, fig.align='center'}
pca_df <- evec_df %>% 
  tidyr::pivot_longer(c(ancestry, grouping), names_to = "grp", values_to = "val")
levels(pca_df$grp) = c("ancestry", "grouping")

plot_legend <- ggplot2::ggplot(subset(pca_df, grp == "ancestry"), aes(x = PC1, y = PC2)) +
  geom_jitter(aes(color = val)) + 
  scale_color_manual(values = brewer.pal(6, "Set2"), name = "ancestry") +
  ggnewscale::new_scale_color() +
  geom_jitter(data = subset(pca_df, grp == "grouping"), aes(color = val)) +
  scale_color_manual(values = brewer.pal(3, "Dark2")[1:2], name = "grouping")

pca_plot <- function(pc_a, pc_b, grp_by) {
  mplot <- ggplot2::ggplot(subset(pca_df, grp == grp_by), aes_string(x = pc_a, y = pc_b)) +
    geom_jitter(aes(color = val)) + theme(legend.position = "none") + xlim(-40, 40) +
    ylim(-40, 40)
  if (grp_by == "ancestry") {
    mplot <- mplot + scale_color_manual(values = brewer.pal(6, "Set2"), name = grp_by)
    } else if (grp_by == "grouping") {
    mplot <- mplot + scale_color_manual(values = brewer.pal(3, "Dark2")[1:2], name = "grouping")
    }
  return(mplot)
  }

pca_matrix <- ggpairs(pca_df, columns = c("PC1", "PC2", "PC3", "PC4", "PC5"),
                    upper = NULL, lower = NULL, diag = NULL, 
                    legend = GGally::grab_legend(plot_legend),
                    progress = F, switch = "x")

for (j in seq(4)) {
  for (i in seq(2, 5)) {
    if (i > j) {
      pca_matrix[i,j] <- pca_plot(paste0("PC", j), paste0("PC", i), "ancestry")
      pca_matrix[j,i] <- pca_plot(paste0("PC", j), paste0("PC", i), "grouping")
    }}
  }

for (i in seq(5)) {
  pca_matrix[i,i] <- ggally_text(
    paste0("PC", i," (", round(pca_pve$pve[i], 3), "%\nof variance\nexplained)"),
    mapping = ggplot2::aes(size = 1), color = I("black")) +
    theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
          axis.ticks = element_blank(), axis.ticks.y = element_blank(), 
          axis.text.y = element_blank())
}

pca_matrix
ggsave("output/03_pca_matrix.png", height = 6, width = 8, device = "png")
```

The labels for each principal component are positioned to correspond to
the axis they're plotted in. For example, to see the ancestry-colored
plot for "PC2 vs PC1", start at the second row at the "PC2" label along
the y-axis at the right of plot then move to the 1st column, where "PC1"
is labeled on the x-axis at the bottom of the plot. The corresponding
plot for labeled vs unlabeled samples can be found by following the
inverse of the previous step or moving diagonally from the first plot.

```{r trees}
trn_tree <- rpart::rpart(ancestry ~ ., data = evec_lbl, method = "class")

plot(as.party(trn_tree))
text(trn_tree)

mywidth <- 2250

ggplot2::ggsave("../output/03_pc_tree.tiff", device = "tiff", units = "px", 
                width = mywidth, height = mywidth * 0.75, dpi = "print")

cp_trn_tree <- rpart::printcp(trn_tree)

projected_tree <- predict(trn_tree, evec_unl, type = "class")
projected_tree

print_tree <- printcp(trn_tree) %>% as.data.frame()

min_cp <- trn_tree$cptable[which.min(trn_tree$cptable[,"xerror"]),"CP"]

ddata <- ggdendro::dendro_data(trn_tree)

ggplot() +
  geom_segment(data = ddata$segments, aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_text(data = ddata$labels, aes(x = x, y = y, label = label), size = 3, vjust = 0) + 
  geom_text(data = ddata$leaf_labels, aes(x = x, y = y, label = label), size = 3, vjust = 1) +
  theme_dendro()

prd_unl_tree <- predict(trn_tree, newdata = evec_unl, type = "class")
prd_unl_knn <- class::knn(train = evec_trn, test = evec_unl, cl = trn_pop, k = 20, prob = F)

evec_unl_new <- dplyr::mutate(evec_unl, prd_knn = prd_unl_knn, prd_tree = prd_unl_tree) %>% 
  dplyr::relocate(prd_knn, prd_tree)

unl_tree <- rpart::rpart(prd_tree ~ PC1 + PC2 + PC3, data = evec_unl_new, method = "class")
udata <- ggdendro::dendro_data(unl_tree)

ggplot() +
  geom_segment(data = udata$segments, aes(x = x, y = y, xend = xend, yend = yend)) +
  geom_text(data = udata$labels, aes(x = x, y = y, label = label), size = 3, vjust = 0) + 
  geom_text(data = udata$leaf_labels, aes(x = x, y = y, label = label), size = 3, vjust = 1) +
  theme_dendro()

### TODO: compare accuracy between two
### make pca of all samples, labeled by knn vs tree

```
